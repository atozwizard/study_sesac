[통합 발표 대본] LLM 경량화: 지능은 남기고 무게는 줄이는 법

1. 도입 (2분)
"안녕하세요. 오늘 제가 공유할 주제는 **'LLM 경량화'**입니다. PEFT에 대한 이야기입니다.

PEFT는(Parameter Efficient Fine-Tuning), 효과적인 미세 조정을 이야기하는 데요, 수천억개 이상의 매개변수를 가진 LLM도 적은 파라미터만 조절해 유사한 성능을 낼 수 있다는 결과를 토대로 제시되는 방법들 입니다.

최근 AI 업계의 가장 큰 고민은 '모델이 너무 크고 비싸다'는 것이랍니다. 아무리 좋은 모델도 우리 회사 서버나 제 노트북에서 돌아가지 않는다면 쓸모가 없으니까요

. 그래서 오늘은 단순히 모델을 작게 만드는 것을 넘어, 지능은 유지하면서 몸집만 줄이는 경량화 기술의 흐름과 주의해야 할 점들을 정리해 보았습니다."

2. 경량화의 기본 기술 (3분)
"가장 먼저 우리가 흔히 접하는 경량화 기술은 **양자화(Quantization)**입니다. 양자화 역시 PEFT의 한 방법론인데요, 비유하자면 고해상도 사진을 용량이 작은 JPG로 압축하듯, 모델의 복잡한 숫자를 단순하게 줄이는 거죠. 이렇게 양자화된 언어 모델은 크기가 줄어들며, 계산의 효율성이 향상된다. 


또 하나는 **가지치기(Pruning)**인데, 신경망에서 큰 역할이 없는 연결을 과감히 끊어내는 방식입니다. 

그리고 지난번 김수경 교수님 세미나에서 언급된 LoRA가 있습니다. 
LoRA(Low Rank Adoption) (낮은 순위 적응)는 PEFT 방법론 중 하나인데, 기존 매개변수 가중치는 그대로 두고 아주 작은 부분만 미세조정해서 비용과 리소스를 절약시키는 '가성비 튜닝'의 대명사죠."

{예상질문 & 답변} Q: 양자화에서 FP32 → INT8로 간다는 건 무슨 의미인가요? A: "**FP32(32비트 부동소수점)**는 아주 미세한 눈금이 있는 긴 자로 숫자를 정밀하게 재는 것이고, **INT8(8비트 정수)**은 눈금이 듬성듬성한 짧은 자로 반올림해서 재는 것입니다. 정밀도는 조금 떨어지지만, 숫자 하나당 공간이 4분의 1로 줄어 메모리가 절약되고, GPU가 소수점보다 정수 계산을 훨씬 빨리 처리하기 때문에 속도가 몇 배나 빨라집니다."

Q: 가지치기(Pruning)를 하면 실제로 GPU 속도가 바로 빨라지나요? A: "사실 무작위로 연결을 끊는 '비정형 가지치기'는 GPU의 병렬 연산 효율을 오히려 떨어뜨릴 수 있습니다. 그래서 실제 속도 향상을 위해서는 일정한 규칙에 따라 뭉텅이로 잘라내는 '구조적 가지치기'가 중요합니다."

3. LoRA의 한계와 DoRA (3분)

"하지만 김수경 교수님께서 세미나 중 말씀하셨듯이, LoRA(Low-Rank Adaptation, 저차원 적응) 방식은 자원을 아끼는 대신 모델이 좀 '멍청해질' 위험이 있습니다. 학습할 수 있는 공간인 'Rank'가 너무 낮으면, 복잡한 논리를 다 담아내지 못하기 때문입니다.

이걸 극복하기 위해 나온 것이 **DoRA(Weight-Decomposed LoRA)**입니다. 가중치의 '크기'와 '방향'을 분리해서 학습하는데, 파라미터는 조금만 쓰면서도 전체 미세조정과 거의 비슷한 지능을 유지할 수 있어 최근 현업에서 선호하는 방식입니다."

{예상질문 & 답변} Q: LoRA와 DoRA의 결정적인 차이가 뭔가요? A: "LoRA는 원래 모델 옆에 작은 **'포스트잇'**을 붙이는 방식 아주 작은 행렬을추가해서 학습하는 방식이라 공간이 좁으면 지능이 제한됩니다. 반면 DoRA는 가중치를 **'크기'**와 **'방향'**으로 쪼개서 학습해요. 우리가 길을 찾을 때 '북쪽으로(방향) 100미터(크기)'라고 설명하는 것과 같죠. 이렇게 나눠서 학습하면 훨씬 정교하게 지능을 유지할 수 있습니다."

4. DeepSeek과 GRPO: 효율화의 정점 (3분)
"최근 DeepSeek-R1이 화제가 된 이유도 이 효율성 때문입니다. 특히 GRPO라는 알고리즘이 핵심인데요. 기존에는 모델이 잘했는지 평가하는 '크리틱 모델'을 따로 띄워야 해서 GPU를 엄청나게 소모했습니다.

딥시크는 이걸 빼버리고, 한 질문에 대해 여러 답을 내놓게 한 뒤 그 그룹 안에서 점수를 매기는 방식을 썼습니다. 자원을 아끼면서도 모델이 스스로 사고하는 과정을 학습시킨 거죠."


{예상질문 & 답변} Q: GRPO가 크리틱 모델 없이 어떻게 학습이 가능한가요? A: "원래는 **'선생님(크리틱)'**이 점수를 매겨줘야 하는데, GRPO는 학생에게 답안지를 여러 개 쓰게 한 뒤 그 그룹 안에서 상대평가를 합니다. '이 답안지는 우리 그룹 평균보다 좋네? 그럼 플러스!' 이런 식이죠. 덕분에 선생님 모델을 띄울 GPU 자원을 아껴서 더 많이 학습할 수 있습니다."



5. 신념의 문제: Good Liar를 경계하라 (2분)
"우리가 경량화를 할 때 꼭 기억해야 할 교수님의 통찰이 있습니다. 바로 'Good Liar' 현상입니다. 모델이 보상을 잘 받으려고 답은 맞히지만, 실제로는 그 명제를 믿지 않는 상태를 말합니다. 경량화 과정에서 모델을 너무 강하게 몰아붙이면 겉으로만 정답인 척하는 현상이 심해질 수 있고, 이는 지능 저하로 이어집니다."

{예상질문 & 답변} Q: 모델이 '믿지 않는 것'을 학습하면 왜 지능이 떨어지나요? A: "사람도 자기 생각과 반대되는 거짓말을 계속 강요받으면 사고 체계가 꼬이듯, 모델도 내부의 **논리 연결망(신념)**과 충돌하는 대답을 억지로 배우면 전체적인 파라미터 분포가 왜곡됩니다. 이 '내적 갈등' 때문에 원래 잘하던 수학이나 논리 문제까지 엉뚱하게 풀게 되는 것이죠."

6. 사례 및 마무리 (2분)
"실제로 국내 업스테이지의 SOLAR 모델은 모델을 효율적으로 합치는 기법(DUS)으로 성공했고, 반면 Llama-3는 너무 과하게 압축했다가 수학 능력이 급락하는 실패를 겪기도 했습니다. 결국 경량화는 단순히 깎는 것이 아니라 모델의 '사고력'을 어떻게 보존하느냐의 싸움입니다."

앞으로 개발자로서 모델을 고를 때 단순히 파라미터 수만 볼 게 아니라, 우리가 쓸 하드웨어에서 양자화 효율이 얼마나 나오는지, 그리고 모델이트레이닝을 거쳐서 '사고의 과정'을 학습했는지를 먼저 확인하는 자세가 필요하겠습니다."