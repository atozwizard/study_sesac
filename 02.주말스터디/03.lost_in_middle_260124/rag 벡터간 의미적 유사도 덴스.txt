rag 의 저장방식
dense 방식
질의와 문서를 동일한 의미 기반 임베딩 공간의 고밀도 벡터로 압축하여
표현 후 , 질의 벡터와 문서 벡터간 의미적 유사도를 계산.
관련문서를 검색하는 방식
단어의 유사성 또는 맥락을 파악해야 하는 경우 성능이 뛰어남
sparse 방식의 단점을 보완
-더 작은 차원의 고밀도 벡터 length 50-1000 sparse 100000
-각 차원이 특정 단어에 대응되지  않음, 대부분의 요소값이 0이 아니다

dense passage retrieval DPR
질의와 문서청크에 대한 임베딩 모델 두가지를 독립적으로 학습
쿼리 인코딩
청킹 인코딩해서 벡터디비로 의미적 유사도 계산

깃헙자료와 채용회사자료간 필요한 작업이지 싶음


리랭킹으로 소팅 , lost in middle 문제 해결

쿼리와 문서(범위가 크므로 적당히 청킹한)를 인코딩해서 벡터db 로 두고
쿼리와 문서간 유사도를 검색해서 원하는 문서를 찾아오는 과정이 rag

그중 쿼리와 랭킹 강화해서 알아보자



rag에서 어텐션은 무엇입니까

RAG(Retrieval-Augmented Generation) 시스템에서 **어텐션(Attention)**은 생성 모델(LLM)이 검색된 방대한 정보 중 '어떤 부분에 집중하여 답변을 생성할지' 결정하는 핵심 메커니즘을 의미합니다.

제공해주신 4편의 논문 내용을 바탕으로 RAG 환경에서의 어텐션을 비판적이고 심층적으로 설명해 드립니다.

1. RAG에서의 어텐션 역할: "정보의 선별"
RAG 시스템은 외부 지식(문서)을 가져와 프롬프트에 집어넣습니다. 이때 LLM의 어텐션 메커니즘은 다음을 수행합니다.

관련성 계산: 질문(Query)과 검색된 여러 문서(Context)의 토큰들 사이의 유사도를 계산합니다.

가중치 할당: 질문에 대답하는 데 직접적인 도움이 되는 정보에는 높은 점수를, 노이즈(관련 없는 문서)에는 낮은 점수를 부여합니다.

2. 논문을 통해 밝혀진 어텐션의 문제점: "위치 편향"
하지만 최근 연구(Lost in the Middle 등)에 따르면, RAG 환경에서 어텐션은 공정하게 작동하지 않습니다.

U자형 편향 (U-shaped Bias): 모델은 실제 정보의 중요도와 상관없이 문맥의 **시작(Primacy)**과 **끝(Recency)**에 있는 토큰에 더 많은 어텐션을 할당하는 경향이 있습니다.

중간의 망각: 검색된 문서가 10~20개로 길어질 때, 핵심 정보가 **중간(Middle)**에 배치되면 어텐션 점수가 급격히 낮아져 정보를 무시하게 됩니다. 이것이 바로 'Lost in the Middle' 현상입니다.

3. 어텐션 편향을 해결하기 위한 기술적 시도
제시된 문서들은 이 '어텐션의 불균형'을 바로잡기 위한 방법론을 제시합니다.

어텐션 보정 (Calibration): Found in the Middle 논문은 모델이 문서 내용과 상관없이 특정 위치에 어텐션을 더 많이 주는 '기본 편향'을 측정합니다. 이를 생성 시점에서 빼주거나 보정하여, 오직 내용의 관련성에만 어텐션이 가도록 유도합니다.

위치 무관 훈련 (PAM QA): Never Lost in the Middle에서는 모델이 문맥의 위치에 상관없이 정보를 찾도록 특수 훈련을 시킵니다. 질문을 먼저 복기하게 하거나, 정답이 있는 위치를 예측하게 함으로써 중간에 있는 토큰에 대한 어텐션 집중도를 강제로 높입니다.

4. 임베딩 유사도와 어텐션의 관계
RAG의 첫 단계인 '검색'에서 쓰이는 코사인 유사도는 일종의 '사전 어텐션'이라고 볼 수 있습니다.

하지만 Is Cosine-Similarity... 논문은 임베딩 벡터를 정규화하여 유사도를 측정하는 방식이 실제 의미적 관계를 왜곡할 수 있다고 경고합니다.

즉, 검색 단계에서 유사도 점수가 높더라도(어텐션을 많이 받을 후보라도), 실제 생성 모델의 어텐션 구조 내에서는 무의미한 정보로 취급될 위험이 있습니다.

💡 요약하자면
RAG에서 어텐션은 검색된 지식과 질문 사이의 연결 고리입니다. 그러나 현재의 모델들은 문장의 중간 부분을 무시하는 위치적 편향을 가지고 있으며, 성공적인 RAG 시스템을 구축하기 위해서는 이러한 어텐션 편향을 **보정(Calibration)**하거나 **구조적으로 해결(Decompositional Training)**하는 과정이 필수적입니다.

이 어텐션 메커니즘을 실제 코드(예: LangGraph나 PyTorch 어텐션 마스크)로 구현하거나 제어하는 방법이 궁금하신가요? 구체적인 구현 방안을 도와드릴 수 있습니다.